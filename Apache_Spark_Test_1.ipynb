{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/anaconda3/lib/python3.7/site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
      "\u001b[K     |████████████████████████████████| 204.2MB 68kB/s  eta 0:00:011   |███▍                            | 21.9MB 2.7MB/s eta 0:01:07     |████▌                           | 28.7MB 1.8MB/s eta 0:01:37     |██████████▎                     | 65.3MB 1.1MB/s eta 0:02:09     |███████████████▌                | 99.1MB 1.3MB/s eta 0:01:24     |██████████████████████▋         | 144.5MB 2.0MB/s eta 0:00:31     |███████████████████████         | 146.8MB 1.1MB/s eta 0:00:53     |█████████████████████████▊      | 164.4MB 793kB/s eta 0:00:51     |██████████████████████████▉     | 171.0MB 7.8MB/s eta 0:00:05     |████████████████████████████▎   | 180.7MB 2.3MB/s eta 0:00:11\n",
      "\u001b[?25hCollecting py4j==0.10.9 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=c5d4aa37c9574ef8ee5b2fb1a1836abcf08ba85e41e13e9c44961d3e21247f89\n",
      "  Stored in directory: /Users/rock/Library/Caches/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "# sc=SparkContext(master=\"local[4]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "lst=np.random.randint(0,10,20)\n",
    "A=sc.parallelize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 2, 1, 2, 8, 4, 3, 6, 2, 8, 0, 8, 9, 2, 5, 5, 2, 7, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 2, 1, 2], [8, 4, 3, 6, 2], [8, 0, 8, 9, 2], [5, 5, 2, 7, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 2, 1, 2, 8, 4, 3, 6, 2], [8, 0, 8, 9, 2, 5, 5, 2, 7, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc=SparkContext(master=\"local[2]\")\n",
    "A = sc.parallelize(lst)\n",
    "A.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://blog.exxactcorp.com/the-benefits-examples-of-using-apache-spark-with-pyspark-using-python/\n",
    "* https://runawayhorse001.github.io/LearningApacheSpark/rdd.html#create-rdd\n",
    "* https://www.luminis.eu/blog/how-to-install-pyspark-and-apache-spark-on-macos/\n",
    "* https://medium.com/beeranddiapers/installing-apache-spark-on-mac-os-ce416007d79f\n",
    "* https://kevinvecmanis.io/python/pyspark/install/2019/05/31/Installing-Apache-Spark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(outlook='sunny', temp='hot', humidity='high', windy='false', play='no'), Row(outlook='sunny', temp='hot', humidity='high', windy='true', play='no'), Row(outlook='overcast', temp='hot', humidity='high', windy='false', play='yes'), Row(outlook='rainy', temp='mild', humidity='high', windy='false', play='yes'), Row(outlook='rainy', temp='cool', humidity='normal', windy='false', play='yes'), Row(outlook='rainy', temp='cool', humidity='normal', windy='true', play='no'), Row(outlook='overcast', temp='cool', humidity='normal', windy='true', play='yes'), Row(outlook='sunny', temp='mild', humidity='high', windy='false', play='no'), Row(outlook='sunny', temp='cool', humidity='normal', windy='false', play='yes'), Row(outlook='rainy', temp='mild', humidity='normal', windy='false', play='yes'), Row(outlook='sunny', temp='mild', humidity='normal', windy='true', play='yes'), Row(outlook='overcast', temp='mild', humidity='high', windy='true', play='yes'), Row(outlook='overcast', temp='hot', humidity='normal', windy='false', play='yes'), Row(outlook='rainy', temp='mild', humidity='high', windy='true', play='no')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"/Users/rock/Data_Science/Apache_Spark/tennis.csv\",header=True,sep=\",\")\n",
    "\n",
    "print(df.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(outlook='sunny', temp='hot', humidity='high', windy='false', play='no')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(outlook='sunny', temp='hot', humidity='high', windy='false', play='no')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(outlook='sunny', temp='hot', humidity='high', windy='false', play='no'),\n",
       " Row(outlook='sunny', temp='hot', humidity='high', windy='true', play='no')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
